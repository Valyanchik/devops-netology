## Домашнее задание к занятию "3.5. Файловые системы"

1. Узнайте о sparse (разряженных) файлах.

Разрежённый файл — файл, в котором последовательности нулевых байтов заменены на информацию об этих последовательностях (список дыр).  
Дыра — последовательность нулевых байт внутри файла, не записанная на диск. Информация о дырах (смещение от начала файла в байтах и количество байт) хранится в метаданных ФС.  
Преимущества:  
•	экономия дискового пространства. Использование разрежённых файлов считается одним из способов сжатия данных на уровне файловой системы;  
•	отсутствие временных затрат на запись нулевых байт;  
•	увеличение срока службы запоминающих устройств.  
Недостатки:  
•	накладные расходы на работу со списком дыр;    
•	фрагментация файла при частой записи данных в дыры;  
•	невозможность записи данных в дыры при отсутствии свободного места на диске;  
•	невозможность использования других индикаторов дыр, кроме нулевых байт.  
Для реализации поддержки разрежённых файлов требуются:  
•	возможность записи метаданных в ФС;  
•	поддержка со стороны системного и прикладного ПО.  
Следующие ФС поддерживают разрежённые файлы: BTRFS, NILFS, ZFS, NTFS, ext2, ext3, ext4, XFS, JFS, ReiserFS, Reiser4, UFS, Rock Ridge, UDF, ReFS, APFS, F2FS.  
Следующее ПО поддерживает работу с разрежёнными файлами:  
•	uTorrent — клиент файлообменной сети, работающей по протоколу BitTorrent;  
•	eMule — клиент файлообменной сети eDonkey2000;  
•	Far manager — файловый менеджер;  
•	VirtualBox — виртуальная машина;  
•	и другое.  
Похожий принцип используется при кодировании аудио-информации, когда тишина (т.е нулевой уровень напряжения или очень низкий) кодируется нулем, таким образом получается сжимать аудио-информацию передавая в канале только указание мест с паузами а не весь  аудио-сигнал

2. Могут ли файлы, являющиеся жесткой ссылкой на один объект, иметь разные права доступа и владельца? Почему?

Жесткая ссылка и файл, для которой она создавалась имеют одинаковые inode. Поэтому жесткая ссылка имеет те же права доступа, владельца и время последней модификации, что и целевой файл, соответственно: разные файлы-hardlink-и в данном случае будут иметь одинаковые права

3. Сделайте vagrant destroy на имеющийся инстанс Ubuntu. Замените содержимое Vagrantfile следующим:

Vagrant.configure("2") do |config|
  config.vm.box = "bento/ubuntu-20.04"  
  config.vm.provider :virtualbox do |vb|  
    lvm_experiments_disk0_path = "/tmp/lvm_experiments_disk0.vmdk"  
    lvm_experiments_disk1_path = "/tmp/lvm_experiments_disk1.vmdk"  
    vb.customize ['createmedium', '--filename', lvm_experiments_disk0_path, '--size', 2560]  
    vb.customize ['createmedium', '--filename', lvm_experiments_disk1_path, '--size', 2560]  
    vb.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', 1, '--device', 0, '--type', 'hdd', '--medium', lvm_experiments_disk0_path]  
    vb.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', 2, '--device', 0, '--type', 'hdd', '--medium', lvm_experiments_disk1_path]  
  end  
end  
Данная конфигурация создаст новую виртуальную машину с двумя дополнительными неразмеченными дисками по 2.5 Гб.

Новый инстанс vagrant с двумя дисками по 2.5 ГБ ![img.png](img.png)  

4. Используя fdisk, разбейте первый диск на 2 раздела: 2 Гб, оставшееся пространство.
Диск sdb разбит на 2 раздела ![img_1.png](img_1.png)

5. Используя sfdisk, перенесите данную таблицу разделов на второй диск.

Процесс переноса таблицы разделов с /dev/sdb на /dev/sdc:

root@vagrant:/home/vagrant# sfdisk -d /dev/sdb | sfdisk --force /dev/sdc  
Checking that no-one is using this disk right now ... OK   

Disk /dev/sdc: 2.51 GiB, 2684354560 bytes, 5242880 sectors  
Disk model: VBOX HARDDISK  
Units: sectors of 1 * 512 = 512 bytes  
Sector size (logical/physical): 512 bytes / 512 bytes  
I/O size (minimum/optimal): 512 bytes / 512 bytes  

>>> Script header accepted.  
>>> Script header accepted.  
>>> Script header accepted.  
>>> Script header accepted.  
>>> Created a new DOS disklabel with disk identifier 0x3813f5f7.  
/dev/sdc1: Created a new partition 1 of type 'Linux' and of size 2 GiB.  
/dev/sdc2: Created a new partition 2 of type 'Linux' and of size 511 MiB.  
/dev/sdc3: Done.  

New situation:  
Disklabel type: dos  
Disk identifier: 0x3813f5f7  

Device     Boot   Start     End Sectors  Size Id Type  
/dev/sdc1          2048 4196351 4194304    2G 83 Linux  
/dev/sdc2       4196352 5242879 1046528  511M 83 Linux  

The partition table has been altered.  
Calling ioctl() to re-read partition table.  
Syncing disks.  
root@vagrant:/home/vagrant# lsblk  
NAME                      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT  
loop0                       7:0    0 55.4M  1 loop /snap/core18/2128  
loop1                       7:1    0 32.3M  1 loop /snap/snapd/12704  
loop2                       7:2    0 70.3M  1 loop /snap/lxd/21029  
loop3                       7:3    0 55.5M  1 loop /snap/core18/2284  
loop4                       7:4    0 43.4M  1 loop /snap/snapd/14549  
loop5                       7:5    0 61.9M  1 loop /snap/core20/1328  
loop6                       7:6    0 67.2M  1 loop /snap/lxd/21835  
sda                         8:0    0   64G  0 disk  
├─sda1                      8:1    0    1M  0 part  
├─sda2                      8:2    0    1G  0 part /boot  
└─sda3                      8:3    0   63G  0 part  
  └─ubuntu--vg-ubuntu--lv 253:0    0 31.5G  0 lvm  /  
sdb                         8:16   0  2.5G  0 disk  
├─sdb1                      8:17   0    2G  0 part  
└─sdb2                      8:18   0  511M  0 part  
sdc                         8:32   0  2.5G  0 disk  
├─sdc1                      8:33   0    2G  0 part  
└─sdc2                      8:34   0  511M  0 part  

6. Соберите mdadm RAID1 на паре разделов 2 Гб.  

Процесс создания RAID массива при помощи утилиты mdadm:  

root@vagrant:/home/vagrant# mdadm --create --verbose /dev/md1 -l 1 -n 2 /dev/sd{b1,c1}  
mdadm: Note: this array has metadata at the start and  
    may not be suitable as a boot device.  If you plan to  
    store '/boot' on this device please ensure that  
    your boot-loader understands md/v1.x metadata, or use  
    --metadata=0.90  
mdadm: size set to 2094080K  
Continue creating array? yes  
mdadm: Defaulting to version 1.2 metadata  
mdadm: array /dev/md1 started.  

7. Соберите mdadm RAID0 на второй паре маленьких разделов.

root@vagrant:/home/vagrant# mdadm --create --verbose /dev/md2 -l 0 -n 2 /dev/sd{b2,c2}  
mdadm: chunk size defaults to 512K  
mdadm: Defaulting to version 1.2 metadata  
mdadm: array /dev/md2 started.  

Получившиеся массивы RAID ![img_2.png](img_2.png)  

8. Создайте 2 независимых PV на получившихся md-устройствах.

Процесс создания physical volume:  
root@vagrant:/home/vagrant# pvcreate /dev/dm1 /dev/md2   
  Device /dev/dm1 not found.  
  Physical volume "/dev/md2" successfully created.  
root@vagrant:/home/vagrant# pvcreate /dev/md1  
  Physical volume "/dev/md1" successfully created.  

9. Создайте общую volume-group на этих двух PV.  

root@vagrant:/home/vagrant# vgcreate vg1 /dev/md1 /dev/md2  
  Volume group "vg1" successfully created  

Получившиеся VG:  

root@vagrant:/home/vagrant# vgdisplay  
  --- Volume group ---  
  VG Name               ubuntu-vg  
  System ID  
  Format                lvm2  
  Metadata Areas        1  
  Metadata Sequence No  2  
  VG Access             read/write  
  VG Status             resizable  
  MAX LV                0  
  Cur LV                1  
  Open LV               1  
  Max PV                0  
  Cur PV                1  
  Act PV                1  
  VG Size               <63.00 GiB  
  PE Size               4.00 MiB  
  Total PE              16127  
  Alloc PE / Size       8064 / 31.50 GiB     
  Free  PE / Size       8063 / <31.50 GiB  
  VG UUID               aK7Bd1-JPle-i0h7-5jJa-M60v-WwMk-PFByJ7  

  --- Volume group ---  
  VG Name               vg1  
  System ID  
  Format                lvm2  
  Metadata Areas        2  
  Metadata Sequence No  1  
  VG Access             read/write  
  VG Status             resizable  
  MAX LV                0  
  Cur LV                0  
  Open LV               0  
  Max PV                0  
  Cur PV                2  
  Act PV                2  
  VG Size               <2.99 GiB  
  PE Size               4.00 MiB  
  Total PE              765  
  Alloc PE / Size       0 / 0  
  Free  PE / Size       765 / <2.99 GiB  
  VG UUID               liEMGw-8piF-t4qu-fbl6-xfg6-Pjut-JfCCZj  


10. Создайте LV размером 100 Мб, указав его расположение на PV с RAID0.  

root@vagrant:/home/vagrant# lvcreate -L 100M vg1 /dev/md2  
  Logical volume "lvol0" created.  

lvo10 ![img_3.png](img_3.png)  

11. Создайте mkfs.ext4 ФС на получившемся LV.  

Создание ФС ext4 на lvo10 ![img_4.png](img_4.png)  

12. Смонтируйте этот раздел в любую директорию, например, /tmp/new.

root@vagrant:/home/vagrant# mkdir /tmp/new  
root@vagrant:/home/vagrant# mount /dev/vg1/lvol0 /tmp/new  

13. Поместите туда тестовый файл, например wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz.

root@vagrant:/home/vagrant# wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz  
--2022-02-06 16:50:28--  https://mirror.yandex.ru/ubuntu/ls-lR.gz  
Resolving mirror.yandex.ru (mirror.yandex.ru)... 213.180.204.183, 2a02:6b8::183  
Connecting to mirror.yandex.ru (mirror.yandex.ru)|213.180.204.183|:443... connected.  
HTTP request sent, awaiting response... 200 OK  
Length: 22110013 (21M) [application/octet-stream]  
Saving to: ‘/tmp/new/test.gz’  

/tmp/new/test.gz              100%[=================================================>]  21.08M  2.63MB/s    in 7.8s  
  
2022-02-06 16:50:36 (2.71 MB/s) - ‘/tmp/new/test.gz’ saved [22110013/22110013]  
  
14. Прикрепите вывод lsblk.

Вывод lsblk после монтирования lvol0 в /tmp/new и копирования в эту директорию файла https://mirror.yandex.ru/ubuntu/ls-lR.gz ![img_5.png](img_5.png)  

15. Протестируйте целостность файла:  

![img_6.png](img_6.png)  

16. Используя pvmove, переместите содержимое PV с RAID0 на RAID1.  

root@vagrant:/home/vagrant# pvmove /dev/md1  
  /dev/md1: Moved: 16.00%  
  /dev/md1: Moved: 100.00%  

17. Сделайте --fail на устройство в вашем RAID1 md.  

root@vagrant:/home/vagrant# mdadm /dev/md1 --fail /dev/sdb1  
mdadm: set /dev/sdb1 faulty in /dev/md1  
root@vagrant:/home/vagrant# mdadm -D /dev/md1  
/dev/md1:  
           Version : 1.2  
     Creation Time : Sun Feb  6 16:26:46 2022  
        Raid Level : raid1  
        Array Size : 2094080 (2045.00 MiB 2144.34 MB)  
     Used Dev Size : 2094080 (2045.00 MiB 2144.34 MB)  
      Raid Devices : 2  
     Total Devices : 2  
       Persistence : Superblock is persistent  

       Update Time : Sun Feb  6 17:04:08 2022  
             State : clean, degraded  
    Active Devices : 1  
   Working Devices : 1  
    Failed Devices : 1  
     Spare Devices : 0  

Consistency Policy : resync  

              Name : vagrant:1  (local to host vagrant)  
              UUID : e92c1d31:b78db98a:f10ea17d:190b3d01  
            Events : 19  

    Number   Major   Minor   RaidDevice State  
       -       0        0        0      removed  
       1       8       33        1      active sync   /dev/sdc1  

       0       8       17        -      faulty   /dev/sdb1  

18. Подтвердите выводом dmesg, что RAID1 работает в деградированном состоянии.

Вывод dmesg при сбойном /dev/sdb1 ![img_7.png](img_7.png)  

19. Протестируйте целостность файла, несмотря на "сбойный" диск он должен продолжать быть доступен:  

Тест целостности файла после перевода /dev/sdb1 в режим fail![img_8.png](img_8.png)  
